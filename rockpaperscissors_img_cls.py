# -*- coding: utf-8 -*-
"""rockpaperscissors-img-cls.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DQQlOmTiDsd3CVygGQjYjaflhiONMoZi
"""

# Commented out IPython magic to ensure Python compatibility.
import os,zipfile,shutil,random
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

# donwload datasets dan simpan di dir /tmp
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

# melakukan ekstraksi pada file zip
zip_path = '/tmp/rockpaperscissors.zip'
unzip = zipfile.ZipFile(zip_path, 'r')
unzip.extractall('/tmp')
unzip.close()

# preparasi pra-modeling
# memisahkan dan membagi data training dan validasi 40%

train_dir = "/tmp/rockpaperscissors/rps-cv-images"
val_dir = "/tmp/rockpaperscissors/val"

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

def select_rand_img_tomove(source, destination, num):
  os.makedirs(destination, exist_ok=True)

  # read semua list dalam source folder
  image_files = os.listdir(source)

  # pilih gambar random dengan jumlah sesuai param num
  images_to_move = random.sample(image_files, num)

  # cut gambar terpilih ke tujuan
  for image in images_to_move:
      source_path = os.path.join(source, image)
      destination_path = os.path.join(destination, image)
      shutil.move(source_path, destination_path)

select_rand_img_tomove(train_dir + "/paper", val_dir + "/paper", 291)
select_rand_img_tomove(train_dir + "/rock", val_dir + "/rock", 291)
select_rand_img_tomove(train_dir + "/scissors", val_dir + "/scissors", 292) # jika di total, maka 874 (40% dari total datasets)

# jadi, folder val di dir /tmp/rockpaperscissors merupakan dir untuk validasi.
# yg merupakan di ambil dari train dir /tmp/rockpaperscissors/rps-cv-images.
# karena data dalam dir itu sudah di ambil / move / cut sebanyak 40%,
# otomatis membuat data yg tersisa di sana adalah datasest train sebanyak 60%.

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',)

test_datagen = ImageDataGenerator(
                    rescale=1./255,)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=4,
        class_mode='categorical') # class mode untuk tugas klasifikasi multi-kelas

validation_generator = train_datagen.flow_from_directory(
        val_dir,
        target_size=(150, 150),
        batch_size=4,
        class_mode='categorical')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax') # karena ini masalah multi-kelas klasifikasi
])

model.summary()

model.compile(loss='categorical_crossentropy', # karena multi-kelas
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

model.fit(
      train_generator,
      steps_per_epoch=32,
      epochs=35, # bisa di tambah untuk meningkatkan akurasinga, namun akan lebih lama
      validation_data=validation_generator,
      validation_steps=8,
      verbose=2)

uploaded = files.upload()

for fn in uploaded.keys():

  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  prediction = model.predict(images)
  print(prediction)
  predicted_class = np.argmax(prediction, axis=1)[0]
  ketagori_kelas = ['PAPER', 'ROCK', 'SCISSORS']
  hasil_kelas_terprediksi = ketagori_kelas[predicted_class]
  print(hasil_kelas_terprediksi)